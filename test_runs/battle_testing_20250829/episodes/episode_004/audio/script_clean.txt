In November 2018, a Chinese scientist named He Jiankui shocked the world. At an international summit on human gene editing, he announced that he had used CRISPR technology to edit the genes of human embryos—and those babies had been born. The scientific community erupted. Not with celebration, but with horror.

This wasn't just about one rogue researcher breaking protocols. It was a mirror that forced the entire scientific community to confront uncomfortable questions they thought they had more time to answer. What it revealed was something fascinating: even the world's leading experts were grappling with fundamental uncertainties about one of the most powerful technologies humans have ever developed.

Today, we're diving into the ethics of CRISPR gene editing—but not to find the "right" answer. Instead, we're exploring why this might be one of those rare cases where the smartest people in the room openly admit they don't know what the right answer is. And why that uncertainty might actually be the most responsible thing they can offer us.

Welcome to Nobody Knows, where we celebrate the questions that don't have easy answers.

Let's start with someone who would know—Jennifer Doudna. She's the Nobel laureate who co-invented CRISPR technology. If anyone has the right to feel confident about gene editing, it's her. But listen to what she says about the current moment: she calls it "an unprecedented scientific opportunity demanding unprecedented ethical responsibility."

Notice what she's not saying. She's not saying "we've got this figured out." She's saying the opposite.

Doudna has become increasingly vocal about something that might surprise you: the limits of scientific control. "We must resist scientific hubris," she warns, "and recognize that our technical control is always partial and provisional—no matter how powerful our methods become."

This is fascinating. Here's the person who created the technology telling us that our control is "partial and provisional." What does she mean by that?

Well, take something called off-target effects. When you use CRISPR to edit genes, the molecular scissors are supposed to cut at specific locations. But sometimes they cut in the wrong places. Ronald Raines at MIT explains: "Cas9 poses a critical safety risk: the active enzyme can linger in cells and cause unintended DNA breaks—so-called off-target effects—which may trigger harmful mutations in healthy genes."

And here's the kicker—we still don't have reliable ways to measure how often this happens. As clinical researchers admit: "No direct method exists to evaluate the percentage of edited cells or identify unintended edits."

So we have this incredibly powerful tool, but we can't always predict exactly what it will do. And the person who invented it is telling us that uncertainty should make us humble, not paralyzed.

Now, from a different angle. Françoise Baylis is one of the world's leading bioethicists, and she's been thinking deeply about gene editing for years. For her, the technical questions are just the beginning.

"It's not just about safety or technical efficacy," Baylis argues, "but about how we define social justice—who benefits, who is at risk, and who gets to decide."

This hits at something profound. Even if we could make gene editing perfectly safe—which we can't yet—we'd still face the question of fairness. If these treatments are expensive, do they create genetic "haves" and "have-nots"? If we can edit out certain traits, what message does that send to people who have those traits?

But here's what makes Baylis's approach so compelling—she doesn't pretend to have all the answers either. When it comes to germline editing—changes that would be passed on to future generations—she's remarkably honest about the limits of our knowledge:

"We simply do not know the lived impact of germline edits on future generations, and that uncertainty must inform, not silence, ethical debate."

Think about that phrase: "uncertainty must inform, not silence, ethical debate." She's arguing that not knowing everything doesn't mean we should stop discussing it. It means we should discuss it more carefully, with more humility, and with more voices at the table.

This connects to something ethicists call the problem of intergenerational consent. If you edit a baby's genes, you're making a decision that will affect not just that child, but potentially all of their descendants. And those future people can't consent to the changes we're making on their behalf.

It's a puzzle that has no clean solution. How do you get consent from people who don't exist yet?

This brings us to voices that are often left out of these conversations—disability rights advocates. Eben Kirksey, an anthropologist who works closely with disability communities, offers a perspective that challenges some of our basic assumptions.

"Disability communities have vital expertise about what it means to live a good life," Kirksey points out, "expertise often ignored by techno-scientific enthusiasm for enhancement."

This is a crucial point. Much of the excitement around gene editing focuses on "fixing" genetic conditions. But disability advocates ask: who decided these conditions need fixing? And what gets lost when we assume that eliminating genetic differences is automatically good?

Kirksey's research reveals something important: many people living with genetic conditions that others might want to "cure" report living fulfilling, meaningful lives. The problem isn't always the condition—it's often society's response to the condition.

But here's what's remarkable about Kirksey's approach. He's not making absolute pronouncements either. Instead, he emphasizes the complexity: "The complexities of embodiment and lived experience mean we must approach CRISPR interventions with care, not certainty, foregrounding community-based knowledge."

Care, not certainty. Community-based knowledge, not just expert opinion. He's arguing that the people who actually live with genetic conditions have expertise that laboratory scientists might not have. And that their voices need to be central to these decisions, not peripheral.

Finally, let's hear from Jonathan Kimmelman, who studies the ethics of clinical trials. He's particularly focused on a question that keeps him up at night: how do we responsibly move from laboratory discoveries to human treatments?

Kimmelman has a framework that I find incredibly useful. He suggests we should constantly ask: "What do we know, what can't we know yet, and how do we responsibly communicate the difference to affected communities?"

This is the heart of intellectual honesty in science. Not just knowing what you know, but knowing what you can't know—and being upfront about that distinction.

Take the challenge of risk-benefit analysis. In medicine, we're supposed to weigh the potential benefits of a treatment against its potential risks. But listen to what clinical researchers admit about gene editing: "Making precise predictions about the future of an edited organism and gauging potential risks and benefits might be difficult, if not impossible."

If it's impossible to make precise predictions, how do we make treatment decisions? Kimmelman's answer is characteristically thoughtful: "Translational hype must be tempered with careful ethical scrutiny rooted in humility about biological complexity."

Notice that he's not saying we should stop researching or stop trying to help patients. He's saying we should proceed with humility about what we don't understand.

Now, here's where it gets really interesting. Each of these perspectives is applying different ethical frameworks to the same technology. And these frameworks sometimes lead to different conclusions—which isn't a bug, it's a feature.

Take a utilitarian approach—trying to achieve the greatest good for the greatest number. This might suggest we should push forward aggressively with gene editing if it can help lots of people. But remember what clinical researchers told us: making precise predictions about benefits and risks "might be difficult, if not impossible." If you can't calculate the costs and benefits accurately, utilitarian analysis becomes a lot more complicated.

From a rights-based or deontological perspective, the central question is different: are we treating people as ends in themselves, or as means to an end? The intergenerational consent problem looms large here. Future persons cannot consent to genetic changes we make today. Does that make germline editing inherently wrong, regardless of the benefits?

Virtue ethics asks yet another question: what kind of people are we becoming through our choices? Jennifer Doudna's emphasis on humility reflects this approach. The virtue isn't just in achieving good outcomes, but in how we conduct ourselves along the way.

And justice-based approaches, like Françoise Baylis's, focus on fairness and equality. Even if gene editing produces good outcomes overall, if those outcomes aren't distributed fairly, we might have a serious ethical problem.

Here's the fascinating thing: each of these frameworks reveals different aspects of the same complex issue. This isn't confusion—it's richness. It's the difference between seeing an issue in black and white versus seeing it in full color.

So where does all this leave us? With a lot of uncertainty. And I want to suggest that this is actually the most valuable thing these experts can offer us.

Let's catalog what we don't know. Technically, we don't know how to completely eliminate off-target effects. We don't have reliable ways to measure editing success in many contexts. As researchers honestly admit, "uncertainties persist regarding its long-term safety."

Ethically, we don't know how to solve the intergenerational consent problem. We don't know how to balance individual benefits against social risks. As J. Benjamin Hurlbut, a science policy scholar, puts it: "Our frameworks for judgment are provisional, evolving alongside the technology itself."

Socially, we don't know how gene editing will affect health disparities. We don't know how different cultures will respond to genetic modification. We can't predict how public opinion will evolve.

But here's the key insight: these uncertainties aren't failures of knowledge. They're honest acknowledgments that enable better decisions.

When Jennifer Doudna admits that technical control is "partial and provisional," she's not undermining confidence in science. She's modeling intellectual honesty. When Françoise Baylis says uncertainty should "inform, not silence" ethical debate, she's showing us how to think responsibly about complex issues.

The most dangerous thing these experts could do would be to pretend they have all the answers when they don't. The most responsible thing they can do is tell us what they don't know, not just what they do.

This creates space for the kind of democratic deliberation that complex ethical issues require. When experts acknowledge uncertainty, it opens the door for broader public engagement. It says: "This isn't just a technical decision that experts can make in isolation. This is a societal choice that requires societal input."

So what does this mean for the future of gene editing?

There are some things experts feel relatively confident about. Somatic gene editing—changes that aren't passed on to future generations—is already helping patients with sickle cell disease and other conditions. These applications seem likely to expand, with careful monitoring and oversight.

But germline editing—heritable changes—remains much more controversial. Recently, leading scientific societies called for a ten-year international moratorium on heritable human genome editing, specifically because of unresolved safety risks and lack of social consensus.

The future will be shaped not just by scientific breakthroughs, but by how we handle the governance challenges. How do we create regulatory frameworks that are flexible enough to adapt to new discoveries but strong enough to prevent rogue actors? How do we ensure that global coordination is possible across cultures with different values?

These aren't questions that have technical answers. They're questions that require ongoing public engagement, democratic deliberation, and yes—intellectual humility about what we can and cannot control.

The goal isn't to eliminate uncertainty—it's to make good decisions despite it. It's to proceed thoughtfully rather than recklessly, with care for the voices and values of all the people who might be affected.

What makes this story so compelling isn't that we don't know all the answers. It's that our experts are honest enough to admit it. In a world full of false certainty, that honesty might be the most radical thing of all.

The most responsible thing experts can do isn't to give us simple answers to complex questions. It's to help us think more clearly about complexity itself.

And that's something nobody knows how to do perfectly. Which is exactly why we need to keep learning together.
