<?xml version="1.0" encoding="UTF-8"?>
<document type="reference" domain="elevenlabs" version="3.0" xmlns="https://ai-podcasts-nobody-knows.com/claude-docs">
    <metadata>
        <title>ElevenLabs WebSocket Streaming Guide (2025)</title>
        <claude-optimization>true</claude-optimization>
        <estimated-time>35 minutes</estimated-time>
        <phase>crawl</phase>
        <priority>medium</priority>
    </metadata>

    <content>
        <section type="reference" id="overview">
            <technical-explanation>
                Comprehensive WebSocket streaming implementation for ElevenLabs real-time audio generation, covering connection management, buffer optimization, adaptive streaming, error recovery, and production deployment patterns for low-latency applications.

                Provides:
                - Complete WebSocket client implementation with async/await patterns
                - Buffer management and chunk scheduling optimization
                - Connection lifecycle management with keep-alive mechanisms
                - Performance monitoring and latency measurement systems
                - Error recovery and reconnection strategies
                - Production-ready streaming architectures
            </technical-explanation>
            <simple-explanation>
                Learn real-time audio streaming - generate audio AS text arrives, not after. Think of traditional API like ordering takeout (place complete order, wait for everything, get all food at once), while WebSocket is like a sushi conveyor belt (chef starts making pieces immediately, you get each piece as it's ready, start eating while more arrives).

                Explains:
                - Why streaming is crucial for responsive AI applications
                - How to set up WebSocket connections with ElevenLabs
                - How to optimize for different types of content
                - How to handle network issues and reconnections
            </simple-explanation>
        </section>

        <section type="reference" id="streaming-benefits">
            <technical-explanation>
                Time to First Byte (TTFB) optimization through chunked processing reduces perceived latency from 3-5 seconds to under 200ms for initial audio delivery, enabling real-time conversational AI and dynamic content adaptation.
            </technical-explanation>
            <simple-explanation>
                Instead of waiting for the whole episode to be generated, you start hearing audio almost immediately - like getting your first piece of sushi in 2 minutes instead of waiting 30 minutes for the whole meal.
            </simple-explanation>

            <comparison>
                <traditional-api>
                    <process>Text (5000 chars) → Wait (3-5 seconds) → Complete Audio</process>
                    <use-case>Batch processing, pre-recorded content</use-case>
                </traditional-api>

                <websocket-stream>
                    <process>Text (chunk 1) → Audio (100ms) → Playing while generating rest</process>
                    <use-case>Real-time interaction, live narration, conversational AI</use-case>
                </websocket-stream>
            </comparison>

            <impact-areas>
                <area name="conversational-ai">Responses feel instant to users</area>
                <area name="live-narration">Start playing before script is complete</area>
                <area name="interactive-podcasts">Dynamic content adaptation possible</area>
                <area name="user-experience">10x perceived speed improvement</area>
            </impact-areas>
        </section>

        <section type="reference" id="websocket-setup">
            <instructions>
                <step validation-command="pip show websocket-client">
                    Install WebSocket client: pip install websocket-client
                </step>
                <step validation-command="python -c 'import websocket; print(\"WebSocket import successful\")'">
                    Test WebSocket import capability
                </step>
                <step validation-command="echo $ELEVENLABS_API_KEY">
                    Verify API key is available in environment
                </step>
            </instructions>

            <examples>
                <example type="basic-connection">
                    <scenario>Establishing WebSocket connection to ElevenLabs</scenario>
                    <implementation>
import websocket
import json
import base64

def connect_to_elevenlabs():
    """Establish WebSocket connection"""
    # WebSocket URL with parameters
    voice_id = "21m00Tcm4TlvDq8ikWAM"  # Rachel
    model = "eleven_turbo_v2_5"

    ws_url = (
        f"wss://api.elevenlabs.io/v1/text-to-speech/{voice_id}/stream-input"
        f"?model_id={model}"
    )

    # Headers with authentication
    headers = {
        "xi-api-key": "your_api_key_here"
    }

    # Create connection
    ws = websocket.WebSocketApp(
        ws_url,
        header=headers,
        on_open=on_open,
        on_message=on_message,
        on_error=on_error,
        on_close=on_close
    )

    return ws
                    </implementation>
                    <explanation>Basic WebSocket connection setup with proper authentication and event handler registration</explanation>
                </example>

                <example type="event-handlers">
                    <scenario>WebSocket event handling implementation</scenario>
                    <implementation>
def on_open(ws):
    """Called when connection opens"""
    print("WebSocket connected!")

    # Send initial configuration
    config = {
        "text": " ",  # Start with space to initialize
        "voice_settings": {
            "stability": 0.65,
            "similarity_boost": 0.75
        },
        "generation_config": {
            "chunk_length_schedule": [120, 160, 250]  # Optimized for quality
        }
    }
    ws.send(json.dumps(config))

def on_message(ws, message):
    """Handle incoming audio chunks"""
    data = json.loads(message)

    if data.get("audio"):
        # Decode base64 audio
        audio_chunk = base64.b64decode(data["audio"])
        # Process or play audio chunk
        play_audio_chunk(audio_chunk)

    if data.get("isFinal"):
        print("Audio generation complete!")
                    </implementation>
                    <explanation>Event handlers manage connection lifecycle and process incoming audio data streams</explanation>
                </example>
            </examples>
        </section>

        <section type="reference" id="production-implementation">
            <technical-explanation>
                Production-ready streaming client with asynchronous processing, intelligent buffering, rate limiting, error recovery, and connection management suitable for high-availability applications.
            </technical-explanation>
            <simple-explanation>
                A professional-grade streaming system that can handle real-world problems like network issues, server problems, and high traffic loads.
            </simple-explanation>

            <examples>
                <example type="production-client">
                    <scenario>Complete production WebSocket streaming client</scenario>
                    <implementation>
import asyncio
import websockets
import json
import base64
from queue import Queue
import threading

class ElevenLabsStreamer:
    """Production-ready WebSocket streaming client"""

    def __init__(self, api_key, voice_id="21m00Tcm4TlvDq8ikWAM"):
        self.api_key = api_key
        self.voice_id = voice_id
        self.audio_queue = Queue()
        self.is_streaming = False
        self.buffer = ""
        self.chunk_schedule = [120, 160, 250]  # Characters before generation

    async def stream_text(self, text_generator):
        """Stream text to ElevenLabs and receive audio"""
        url = (
            f"wss://api.elevenlabs.io/v1/text-to-speech/{self.voice_id}/stream-input"
            f"?model_id=eleven_turbo_v2_5"
        )

        headers = {"xi-api-key": self.api_key}

        async with websockets.connect(url, extra_headers=headers) as websocket:
            self.is_streaming = True

            # Send initial config
            await self._send_config(websocket)

            # Start audio receiver task
            receiver_task = asyncio.create_task(
                self._receive_audio(websocket)
            )

            # Stream text chunks
            async for text_chunk in text_generator:
                await self._send_text_chunk(websocket, text_chunk)

            # Send final flush
            await self._flush_buffer(websocket)

            # Wait for all audio
            await receiver_task

    async def _send_config(self, websocket):
        """Send initial configuration"""
        config = {
            "text": " ",
            "voice_settings": {
                "stability": 0.65,
                "similarity_boost": 0.75,
                "style": 0.30
            },
            "generation_config": {
                "chunk_length_schedule": self.chunk_schedule
            }
        }
        await websocket.send(json.dumps(config))

    async def _send_text_chunk(self, websocket, text):
        """Send text chunk with smart buffering"""
        self.buffer += text

        # Check if buffer reached threshold
        if len(self.buffer) >= self.chunk_schedule[0]:
            message = {
                "text": self.buffer,
                "flush": False
            }
            await websocket.send(json.dumps(message))
            self.buffer = ""

    async def _receive_audio(self, websocket):
        """Receive and queue audio chunks"""
        try:
            async for message in websocket:
                data = json.loads(message)

                if "audio" in data:
                    audio_chunk = base64.b64decode(data["audio"])
                    self.audio_queue.put(audio_chunk)

                if data.get("isFinal"):
                    self.is_streaming = False
                    break

        except Exception as e:
            print(f"Receive error: {e}")
            self.is_streaming = False
                    </implementation>
                    <explanation>Complete production client with proper async handling, buffering, and error management</explanation>
                </example>
            </examples>
        </section>

        <section type="reference" id="buffer-optimization">
            <technical-explanation>
                Chunk length scheduling optimization balances latency vs quality trade-offs through strategic buffer sizing based on content type, network conditions, and quality requirements.
            </technical-explanation>
            <simple-explanation>
                How to control the balance between speed and quality - like choosing how much text to collect before turning it into audio.
            </simple-explanation>

            <chunk-schedules>
                <schedule name="aggressive" latency="~100ms" quality="lower">
                    <values>[50, 50, 100, 100]</values>
                    <use-case>Real-time conversation, interactive applications</use-case>
                </schedule>

                <schedule name="balanced" latency="~250ms" quality="good">
                    <values>[120, 160, 250, 290]</values>
                    <use-case>Podcast production, general streaming</use-case>
                </schedule>

                <schedule name="quality" latency="~400ms" quality="highest">
                    <values>[250, 350, 450, 500]</values>
                    <use-case>Professional narration, final production</use-case>
                </schedule>
            </chunk-schedules>

            <examples>
                <example type="dynamic-buffering">
                    <scenario>Adaptive buffering based on content type</scenario>
                    <implementation>
class AdaptiveBuffering:
    """Dynamically adjust buffering based on content"""

    def __init__(self):
        self.base_schedule = [120, 160, 250, 290]
        self.current_schedule = self.base_schedule.copy()

    def adjust_for_content(self, text):
        """Adjust buffer based on content type"""
        # Shorter buffers for dialogue
        if self._is_dialogue(text):
            self.current_schedule = [80, 120, 160, 200]

        # Longer buffers for narration
        elif self._is_narration(text):
            self.current_schedule = [200, 280, 350, 400]

        # Default for mixed content
        else:
            self.current_schedule = self.base_schedule.copy()

        return self.current_schedule

    def _is_dialogue(self, text):
        """Check if text is dialogue"""
        dialogue_markers = ['"', "'", "said", "asked", "replied"]
        return any(marker in text for marker in dialogue_markers)

    def _is_narration(self, text):
        """Check if text is narration"""
        narration_markers = ["once upon", "the story", "narrator:"]
        return any(marker in text.lower() for marker in narration_markers)
                    </implementation>
                    <explanation>Content-aware buffering adjusts chunk sizes dynamically based on text characteristics</explanation>
                </example>
            </examples>
        </section>

        <section type="reference" id="connection-management">
            <technical-explanation>
                Connection lifecycle management including keep-alive mechanisms, timeout handling, graceful disconnection, and automatic reconnection strategies for robust streaming operations.
            </technical-explanation>
            <simple-explanation>
                How to keep the connection alive and handle problems like network drops or server restarts automatically.
            </simple-explanation>

            <examples>
                <example type="keep-alive">
                    <scenario>Connection keep-alive during idle periods</scenario>
                    <implementation>
class ConnectionManager:
    """Manage WebSocket connection lifecycle"""

    def __init__(self, timeout_seconds=20):
        self.timeout = timeout_seconds
        self.last_activity = time.time()
        self.keep_alive_task = None

    async def start_keep_alive(self, websocket):
        """Keep connection alive during idle periods"""
        self.keep_alive_task = asyncio.create_task(
            self._keep_alive_loop(websocket)
        )

    async def _keep_alive_loop(self, websocket):
        """Send periodic keep-alive messages"""
        while True:
            await asyncio.sleep(15)  # Check every 15 seconds

            time_since_activity = time.time() - self.last_activity

            if time_since_activity > 15:
                # Send single space to keep alive
                keep_alive = {"text": " "}
                await websocket.send(json.dumps(keep_alive))
                print("Sent keep-alive")

    def update_activity(self):
        """Update last activity timestamp"""
        self.last_activity = time.time()
                    </implementation>
                    <explanation>Keep-alive system prevents connection timeouts during periods of inactivity</explanation>
                </example>

                <example type="resilient-streaming">
                    <scenario>Automatic reconnection on connection failure</scenario>
                    <implementation>
class ResilientStreamer:
    """Streaming with automatic reconnection"""

    def __init__(self, api_key, max_retries=3):
        self.api_key = api_key
        self.max_retries = max_retries

    async def stream_with_retry(self, text_generator):
        """Stream with automatic retry on failure"""
        for attempt in range(self.max_retries):
            try:
                streamer = ElevenLabsStreamer(self.api_key)
                await streamer.stream_text(text_generator)
                return  # Success

            except websockets.ConnectionClosed as e:
                print(f"Connection closed: {e}")
                if attempt < self.max_retries - 1:
                    wait_time = 2 ** attempt
                    print(f"Retrying in {wait_time}s...")
                    await asyncio.sleep(wait_time)
                else:
                    raise

            except Exception as e:
                print(f"Streaming error: {e}")
                raise
                    </implementation>
                    <explanation>Resilient streaming with exponential backoff retry strategy for connection failures</explanation>
                </example>
            </examples>
        </section>

        <section type="reference" id="performance-monitoring">
            <technical-explanation>
                Performance monitoring system tracking Time to First Byte (TTFB), chunk processing efficiency, throughput metrics, and streaming quality indicators for optimization and debugging.
            </technical-explanation>
            <simple-explanation>
                How to measure how well your streaming is working - like having a speedometer for your audio generation.
            </simple-explanation>

            <examples>
                <example type="latency-tracking">
                    <scenario>Comprehensive streaming performance measurement</scenario>
                    <implementation>
class LatencyTracker:
    """Track streaming performance metrics"""

    def __init__(self):
        self.first_text_time = None
        self.first_audio_time = None
        self.chunks_sent = 0
        self.chunks_received = 0

    def mark_text_sent(self):
        """Mark when first text is sent"""
        if not self.first_text_time:
            self.first_text_time = time.time()
        self.chunks_sent += 1

    def mark_audio_received(self):
        """Mark when first audio arrives"""
        if not self.first_audio_time and self.first_text_time:
            self.first_audio_time = time.time()
        self.chunks_received += 1

    def get_ttfb(self):
        """Get Time To First Byte"""
        if self.first_text_time and self.first_audio_time:
            return self.first_audio_time - self.first_text_time
        return None

    def get_metrics(self):
        """Get all metrics"""
        return {
            "ttfb": self.get_ttfb(),
            "chunks_sent": self.chunks_sent,
            "chunks_received": self.chunks_received,
            "efficiency": self.chunks_received / max(self.chunks_sent, 1)
        }
                    </implementation>
                    <explanation>Performance tracking system measures latency and efficiency for optimization</explanation>
                </example>
            </examples>
        </section>

        <section type="troubleshooting" id="common-issues">
            <examples>
                <example type="anti-pattern">
                    <scenario>Connection drops during streaming</scenario>
                    <implementation>WebSocket connections timing out or closing unexpectedly</implementation>
                    <explanation>Implement keep-alive mechanism and connection monitoring with automatic reconnection</explanation>
                </example>

                <example type="anti-pattern">
                    <scenario>Audio choppy or inconsistent quality</scenario>
                    <implementation>Poor buffer management or inappropriate chunk scheduling</implementation>
                    <explanation>Adjust chunk_length_schedule based on content type and network conditions</explanation>
                </example>

                <example type="anti-pattern">
                    <scenario>High latency despite streaming</scenario>
                    <implementation>Buffers too large or network issues</implementation>
                    <explanation>Use aggressive chunk scheduling and implement latency monitoring</explanation>
                </example>
            </examples>

            <validation>
                <validation-command>python -c "import asyncio; import websockets; print('WebSocket libraries available')"</validation-command>
                <success-criteria>WebSocket streaming client connects successfully and receives audio chunks</success-criteria>
            </validation>
        </section>

        <section type="advanced" id="advanced-usage">
            <technical-explanation>
                Advanced streaming patterns including parallel streams for segments, adaptive quality based on network conditions, audio caching strategies, and fallback mechanisms for production deployment.
            </technical-explanation>
            <simple-explanation>
                Professional techniques for complex streaming scenarios - like having multiple audio streams running at once or automatically adjusting quality based on internet speed.
            </simple-explanation>

            <examples>
                <example type="advanced">
                    <scenario>Real-time podcast streaming with buffering</scenario>
                    <implementation>
class PodcastStreamer:
    """Stream podcast audio in real-time"""

    def __init__(self, api_key):
        self.streamer = ElevenLabsStreamer(api_key)
        self.audio_player = AudioPlayer()  # Your audio player

    async def stream_episode(self, script_generator):
        """Stream episode as it's being generated"""
        print("Starting real-time podcast stream...")

        # Start streaming task
        stream_task = asyncio.create_task(
            self.streamer.stream_text(script_generator)
        )

        # Start playing audio as it arrives
        play_task = asyncio.create_task(
            self._play_audio_stream()
        )

        # Wait for both to complete
        await asyncio.gather(stream_task, play_task)

        print("Episode streaming complete!")

    async def _play_audio_stream(self):
        """Play audio chunks as they arrive"""
        audio_buffer = []
        min_buffer_size = 3  # Buffer 3 chunks before starting

        while self.streamer.is_streaming or not self.streamer.audio_queue.empty():
            # Get audio chunk
            chunk = self.streamer.get_audio_chunk()

            if chunk:
                audio_buffer.append(chunk)

                # Start playing once we have enough buffered
                if len(audio_buffer) >= min_buffer_size:
                    combined = b''.join(audio_buffer[:min_buffer_size])
                    self.audio_player.play(combined)
                    audio_buffer = audio_buffer[min_buffer_size:]

            await asyncio.sleep(0.01)

        # Play remaining audio
        if audio_buffer:
            self.audio_player.play(b''.join(audio_buffer))
                    </implementation>
                    <explanation>Real-time streaming with buffering strategy for smooth audio playback during generation</explanation>
                </example>
            </examples>
        </section>
    </content>

    <cross-references>
        <reference file="00_elevenlabs_constants.xml" section="websocket-endpoints" type="prerequisite">
            WebSocket endpoints and connection parameters
        </reference>
        <reference file="18_elevenlabs_api_implementation.xml" section="async-implementation" type="prerequisite">
            Asynchronous programming patterns with ElevenLabs
        </reference>
        <reference file="20_elevenlabs_cost_optimization.xml" section="streaming-efficiency" type="related">
            Cost optimization strategies for streaming
        </reference>
        <reference file="23_elevenlabs_podcast_production.xml" section="real-time-generation" type="application">
            Streaming integration in podcast production workflows
        </reference>
    </cross-references>
</document>
