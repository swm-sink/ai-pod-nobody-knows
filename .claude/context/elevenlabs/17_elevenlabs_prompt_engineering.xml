<?xml version="1.0" encoding="UTF-8"?>
<document type="reference" domain="elevenlabs" version="3.0" xmlns="https://ai-podcasts-nobody-knows.com/claude-docs">
    <metadata>
        <title>ElevenLabs Prompt Engineering &amp; Voice Control (2025)</title>
        <claude-optimization>true</claude-optimization>
        <estimated-time>25 minutes</estimated-time>
        <phase>crawl</phase>
        <priority>high</priority>
    </metadata>

    <content>
        <section type="reference" id="overview">
        </section>

        <section type="reference" id="core-principles">

            <examples>
                <example type="anti-pattern">
                    <scenario>Insufficient context for AI voice processing</scenario>
                    <implementation>❌ "Hello."</implementation>
                    <explanation>Too short - AI can't determine tone, pace, or emotional delivery</explanation>
                </example>

                <example type="good-practice">
                    <scenario>Proper context establishment</scenario>
                    <implementation>✅ "Hello, and welcome to Nobody Knows, the podcast that explores the vast ocean of human ignorance with curiosity and humility. I'm your host, and today we're diving into a fascinating paradox: the more we learn, the more we realize we don't know."</implementation>
                    <explanation>250+ characters provide sufficient context for natural prosody and appropriate delivery tone</explanation>
                </example>
            </examples>
        </section>

        <section type="reference" id="audio-tags">

            <available-tags>
                <emotion-tags>
                    <tag name="whispers">Reduces volume and adds intimacy</tag>
                    <tag name="laughs">Inserts natural laughter</tag>
                    <tag name="sighs">Adds contemplative breath</tag>
                    <tag name="excited">Increases energy and pace</tag>
                    <tag name="thoughtful">Slower, more deliberate delivery</tag>
                    <tag name="sarcastic">Adds ironic tone inflection</tag>
                </emotion-tags>

                <pacing-tags>
                    <tag name="pauses">Brief natural pause</tag>
                    <tag name="speaking quickly">Increased delivery speed</tag>
                    <tag name="slowly">Deliberate paced delivery</tag>
                    <tag name="clears throat">Natural throat clearing sound</tag>
                </pacing-tags>
            </available-tags>

            <examples>
                <example type="suspense">
                    <scenario>Building dramatic tension</scenario>
                    <implementation>"The data was conclusive... [pauses] or so we thought. [whispers] But hidden in the footnotes was something nobody noticed. [clears throat] Let me read it exactly as written: [normal voice] 'Results may vary under conditions not tested.' [sighs] Those seven words changed everything."</implementation>
                    <explanation>Progressive emotional build using pauses, whispers, and vocal transitions</explanation>
                </example>

                <example type="personality">
                    <scenario>Adding character and humor</scenario>
                    <implementation>"So the physicist walks into the bar [laughs] - I know, I know, another physics joke - but hear me out! [clears throat] He orders a beer that exists in quantum superposition. The bartender says [pauses] 'That'll be $5 and not $5 simultaneously.' [laughs harder] Okay, maybe you had to be there... [sighs]"</implementation>
                    <explanation>Natural personality expression through laughter, pauses, and emotional reactions</explanation>
                </example>
            </examples>
        </section>

        <section type="reference" id="voice-settings">

            <settings-explained>
                <setting name="stability" range="0-100">
                    <description>Controls voice variation vs consistency</description>
                    <simple-analogy>Like choosing between a jazz musician (low stability, creative) vs a classical musician (high stability, precise)</simple-analogy>
                    <podcast-recommendation>50-70% for natural but reliable narration</podcast-recommendation>
                </setting>

                <setting name="similarity_boost" range="0-100">
                    <description>How closely to match original voice characteristics</description>
                    <simple-analogy>Like an impressionist - higher settings mean closer mimicry</simple-analogy>
                    <podcast-recommendation>75-85% for consistency across episodes</podcast-recommendation>
                </setting>

                <setting name="style_exaggeration" range="0-100" model-requirement="v3 only">
                    <description>Amplifies emotional expression and prosodic features</description>
                    <simple-analogy>Like choosing between understated acting vs theatrical performance</simple-analogy>
                    <podcast-recommendation>20-40% for engaging but natural delivery</podcast-recommendation>
                </setting>
            </settings-explained>

            <content-type-presets>
                <preset type="interview">
                    <stability>45-55</stability>
                    <similarity>75</similarity>
                    <style>20</style>
                    <use-case>Conversational, natural variation</use-case>
                </preset>

                <preset type="narration">
                    <stability>60-70</stability>
                    <similarity>80</similarity>
                    <style>30</style>
                    <use-case>Storytelling, engaging delivery</use-case>
                </preset>

                <preset type="educational">
                    <stability>70-80</stability>
                    <similarity>85</similarity>
                    <style>10</style>
                    <use-case>Clear, consistent, professional</use-case>
                </preset>
            </content-type-presets>
        </section>

        <section type="reference" id="pronunciation-control">

            <methods>
                <method name="ssml-phonemes" compatibility="Flash v2, Turbo v2, English v1">
                    <description>Technical phonetic notation for precise pronunciation control</description>
                    <example type="cmu-arpabet">
                        <code>&lt;phoneme alphabet="cmu" ph="T R AE P AH Z IY">trapezii&lt;/phoneme></code>
                    </example>
                    <example type="ipa">
                        <code>&lt;phoneme alphabet="ipa" ph="trəˈpiːzi">trapezii&lt;/phoneme></code>
                    </example>
                </method>

                <method name="pronunciation-dictionaries" compatibility="All models">
                    <description>JSON-based word replacement system</description>
                    <example type="dictionary">
                        <code language="json">
{
  "pronunciations": [
    {
      "word": "Kubernetes",
      "replacement": "koo-ber-net-eez"
    },
    {
      "word": "PostgreSQL",
      "replacement": "post-gres-Q-L"
    },
    {
      "word": "AI",
      "replacement": "artificial intelligence"
    }
  ]
}
                        </code>
                    </example>
                </method>

                <method name="creative-text-manipulation" compatibility="All models">
                    <description>Strategic text modification for better pronunciation</description>
                    <examples>
                        <transformation from="The API returned an error" to="The A.P.I. returned an error"/>
                        <transformation from="nginx server" to="engine-x server"/>
                    </examples>
                </method>
            </methods>
        </section>

        <section type="reference" id="prompt-patterns">
            <instructions>
                <step validation-command="echo 'Testing context sandwich pattern'">
                    Context Sandwich: Setup context + main content + context reinforcement
                </step>
                <step validation-command="echo 'Testing rhythm markers'">
                    Rhythm Markers: Vary sentence length (short, longer, short) for natural flow
                </step>
                <step validation-command="echo 'Testing emotional arcs'">
                    Emotional Arcs: Start neutral → build interest → peak excitement → thoughtful conclusion
                </step>
            </instructions>

            <examples>
                <example type="context-sandwich">
                    <scenario>Establishing expert authority</scenario>
                    <implementation>"Speaking as someone who's studied this for decades, [Main points about quantum mechanics] which is why, after all these years, I'm still amazed."</implementation>
                    <explanation>Context establishes credibility, reinforcement maintains authority throughout</explanation>
                </example>

                <example type="rhythm-markers">
                    <scenario>Preventing monotonous delivery</scenario>
                    <implementation>"Short sentence. Longer sentence with more detail and explanation. Back to short. This creates natural rhythm. It prevents monotony. And it keeps listeners engaged throughout the episode."</implementation>
                    <explanation>Sentence length variation mimics natural speech patterns</explanation>
                </example>

                <example type="emotional-arc">
                    <scenario>Engaging narrative structure</scenario>
                    <implementation>"Let's discuss memory. [neutral] But not just any memory - the kind that changes who you are. [building] Imagine losing everything you know, every face, every name! [peak] [pauses] Yet somehow... still being you. [thoughtful]"</implementation>
                    <explanation>Emotional progression maintains listener engagement and creates memorable moments</explanation>
                </example>
            </examples>
        </section>

        <section type="reference" id="podcast-specific-techniques">

            <templates>
                <template type="opening-hook">
                    <code language="python">
def create_opening(topic, emotion="curious"):
    return f"""
    [clears throat] Have you ever wondered about {topic}?
    [pauses] I mean, really wondered - to the point where you
    question everything you thought you knew? [voice rises slightly]
    Welcome to Nobody Knows, where we embrace the beautiful uncertainty
    of human knowledge. [warm tone] I'm your host, and today...
    [voice drops, {emotion}] we're going somewhere unexpected.
    """
                    </code>
                </template>

                <template type="transitions">
                    <smooth>"Which brings us naturally to..."</smooth>
                    <dramatic>"[pauses] But wait. [voice drops] There's more."</dramatic>
                    <questioning>"So you might be wondering..."</questioning>
                    <surprising>"[laughs] Okay, this next part surprised even me..."</surprising>
                </template>

                <template type="closings">
                    <reflective>"[sighs thoughtfully] So what have we learned?"</reflective>
                    <call-to-action>"Your homework, should you choose to accept it..."</call-to-action>
                    <teaser>"[whispers] Next week's episode will blow your mind..."</teaser>
                    <open-ended>"I'll leave you with this thought..."</open-ended>
                </template>
            </templates>
        </section>

        <section type="troubleshooting" id="common-issues">
            <examples>
                <example type="anti-pattern">
                    <scenario>Inconsistent emotional delivery</scenario>
                    <implementation>Single emotional tag without sufficient context</implementation>
                    <explanation>Ensure 250+ character context around emotional tags for consistent processing</explanation>
                </example>

                <example type="anti-pattern">
                    <scenario>Persistent mispronunciations</scenario>
                    <implementation>Relying solely on correct spelling</implementation>
                    <explanation>Use pronunciation dictionaries or creative spelling: "engine-x" for "nginx"</explanation>
                </example>

                <example type="anti-pattern">
                    <scenario>Robotic or monotonous delivery</scenario>
                    <implementation>Uniform sentence structure and length</implementation>
                    <explanation>Vary sentence length and add natural breaks with ellipses (...)</explanation>
                </example>
            </examples>

            <validation>
                <validation-command>curl -X POST "https://api.elevenlabs.io/v1/text-to-speech/VOICE_ID" -H "Content-Type: application/json" -d '{"text":"Test pronunciation and delivery"}'</validation-command>
                <success-criteria>Generated audio with natural prosody and correct pronunciations</success-criteria>
            </validation>
        </section>

        <section type="advanced" id="advanced-techniques">

            <examples>
                <example type="advanced">
                    <scenario>Multi-voice conversation simulation</scenario>
                    <implementation>
def create_dialogue(speaker1_text, speaker2_text):
    return f"""
    [Voice: Alex] {speaker1_text}
    [Voice: Sam] [different energy] {speaker2_text}
    [Voice: Alex] [reacting to Sam] Interesting point...
    """
                    </implementation>
                    <explanation>Create conversational dynamics using voice switching and energy variations</explanation>
                </example>

                <example type="dynamic-pacing">
                    <scenario>Variable delivery speed for emphasis</scenario>
                    <implementation>Fast section... [speaking quickly] when excitement builds... [normal pace] returning to baseline... [slowly, deliberately] when... making... a... crucial... point.</implementation>
                    <explanation>Pacing variation draws attention to important concepts and maintains engagement</explanation>
                </example>

                <example type="contextual-emphasis">
                    <scenario>Word emphasis through placement and capitalization</scenario>
                    <implementation>
The answer isn't what you'd expect.
The ANSWER isn't what you'd expect.
The answer ISN'T what you'd expect.
The answer isn't what YOU'D expect.
                    </implementation>
                    <explanation>Different emphasis patterns create different meanings and emotional impacts</explanation>
                </example>
            </examples>
        </section>

        <section type="reference" id="implementation-code">
            <code-examples>
                <example type="prompt-optimization">
                    <code language="python">
def optimize_prompt(text, style="podcast"):
    """Enhances text for better AI narration"""
    # Ensure minimum length
    if len(text) &lt; 250:
        text = add_context(text)

    # Add style-specific markers
    if style == "podcast":
        text = add_podcast_markers(text)
    elif style == "educational":
        text = add_educational_structure(text)

    # Check for problem words
    text = fix_pronunciations(text)

    # Add emotional arc if long
    if len(text) > 1000:
        text = add_emotional_journey(text)

    return text
                    </code>
                </example>

                <example type="voice-settings-config">
                    <code language="python">
VOICE_SETTINGS = {
    "podcast_host": {
        "stability": 0.65,
        "similarity_boost": 0.75,
        "style": 0.30,
        "use_speaker_boost": True
    },
    "narrator": {
        "stability": 0.70,
        "similarity_boost": 0.80,
        "style": 0.20,
        "use_speaker_boost": False
    },
    "character": {
        "stability": 0.50,
        "similarity_boost": 0.70,
        "style": 0.40,
        "use_speaker_boost": True
    }
}
                    </code>
                </example>
            </code-examples>
        </section>
    </content>

    <cross-references>
        <reference file="00_elevenlabs_constants.xml" section="audio-tags" type="prerequisite">
            Complete audio tags specifications and model compatibility
        </reference>
        <reference file="16_elevenlabs_models_reference.xml" section="model-comparison" type="prerequisite">
            Model capabilities and compatibility information
        </reference>
        <reference file="20_elevenlabs_cost_optimization.xml" section="efficiency" type="related">
            Cost optimization through prompt engineering
        </reference>
        <reference file="23_elevenlabs_podcast_production.xml" section="workflow" type="application">
            Application in podcast production workflows
        </reference>
    </cross-references>
</document>
