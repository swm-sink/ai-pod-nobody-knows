<?xml version="1.0" encoding="UTF-8"?>
<document type="reference" domain="elevenlabs" version="3.0" xmlns="https://ai-podcasts-nobody-knows.com/claude-docs">
    <metadata>
        <title>ElevenLabs Models Reference Guide (2025)</title>
        <claude-optimization>true</claude-optimization>
        <estimated-time>15 minutes</estimated-time>
        <phase>crawl</phase>
        <priority>high</priority>
    </metadata>

    <content>
        <section type="reference" id="overview">
            <technical-explanation>
                Comprehensive reference for ElevenLabs voice synthesis models, including performance characteristics, cost analysis, and optimal use cases for professional podcast production. Covers model specifications, latency metrics, language support, and implementation patterns for production systems.

                Provides:
                - Complete model comparison matrices with 2025 specifications
                - Cost-per-episode calculations for podcast production
                - Technical API implementation patterns
                - Performance benchmarking data
                - Migration strategies across development phases
            </technical-explanation>
            <simple-explanation>
                Think of this as your guide to picking the right voice tool - like choosing between a quick sketch, a detailed drawing, or a professional painting based on what you need.

                Explains:
                - Which ElevenLabs model to choose and when
                - How much each model costs for your podcast
                - What makes each model special
                - How to switch between models as you grow
            </simple-explanation>
        </section>

        <section type="reference" id="model-comparison">
            <technical-explanation>
                Model performance matrix with quantitative metrics for speed, quality, language support, and cost optimization. All values reference constants file for maintainability.
            </technical-explanation>
            <simple-explanation>
                Like comparing different types of cameras - phone camera (quick, decent), DSLR (better quality, moderate price), or cinema camera (amazing quality, premium price).
            </simple-explanation>

            <comparison-matrix>
                <model id="flash_v25">
                    <speed>~75ms latency</speed>
                    <quality>Good</quality>
                    <languages>32</languages>
                    <cost>50% less than Turbo</cost>
                    <best-for>Real-time, Budget, Testing</best-for>
                    <character-limit>40,000</character-limit>
                </model>

                <model id="turbo_v2">
                    <speed>~200ms latency</speed>
                    <quality>Better</quality>
                    <languages>English only</languages>
                    <cost>Standard pricing</cost>
                    <best-for>English podcasts, Stability</best-for>
                    <character-limit>40,000</character-limit>
                </model>

                <model id="turbo_v25">
                    <speed>~250ms latency</speed>
                    <quality>Better</quality>
                    <languages>32 including Vietnamese, Hungarian</languages>
                    <cost>Same as Turbo v2</cost>
                    <best-for>Multilingual content, Future-proof</best-for>
                    <character-limit>40,000</character-limit>
                </model>

                <model id="eleven_v3">
                    <speed>~400ms latency</speed>
                    <quality>Best</quality>
                    <languages>70+</languages>
                    <cost>80% discount until June 2025</cost>
                    <best-for>Premium, Emotional, Storytelling</best-for>
                    <character-limit>50,000</character-limit>
                </model>
            </comparison-matrix>
        </section>

        <section type="reference" id="cost-analysis">
            <technical-explanation>
                Per-episode cost calculations based on 27-minute episodes (approximately 27,000 characters) with scaling projections for production volumes.
            </technical-explanation>
            <simple-explanation>
                Real dollar amounts for what it costs to make your podcast episodes with each model.
            </simple-explanation>

            <cost-breakdown>
                <episode-costs characters="27000">
                    <model name="Flash v2.5" cost-per-episode="6.75" monthly-4-episodes="27.00" hundred-episodes="675.00"/>
                    <model name="Turbo v2/v2.5" cost-per-episode="13.50" monthly-4-episodes="54.00" hundred-episodes="1350.00"/>
                    <model name="Eleven v3 (discounted)" cost-per-episode="5.40" monthly-4-episodes="21.60" hundred-episodes="540.00"/>
                    <model name="Eleven v3 (normal)" cost-per-episode="27.00" monthly-4-episodes="108.00" hundred-episodes="2700.00"/>
                </episode-costs>
            </cost-breakdown>
        </section>

        <section type="reference" id="decision-tree">
            <instructions>
                <step validation-command="echo 'Testing phase requirements'">
                    For Testing/Development: Use Flash v2.5 (cheapest, fastest iteration)
                </step>
                <step validation-command="echo 'Production language requirements'">
                    For English Only Production: Choose between Turbo v2 (stable) or Eleven v3 (emotional, currently discounted)
                </step>
                <step validation-command="echo 'Multilingual requirements'">
                    For Multiple Languages: Choose between Turbo v2.5 (stable, recommended) or Eleven v3 (emotional)
                </step>
            </instructions>

            <examples>
                <example type="basic">
                    <scenario>English-only podcast with good quality needs</scenario>
                    <implementation>eleven_turbo_v2 or eleven_v3_alpha (while discounted)</implementation>
                    <explanation>Turbo v2 optimized for English; v3 adds emotion at lower cost due to discount</explanation>
                </example>

                <example type="multilingual">
                    <scenario>Podcast planning international versions</scenario>
                    <implementation>eleven_turbo_v2_5</implementation>
                    <explanation>Same cost as English-only but supports 32 languages for future expansion</explanation>
                </example>
            </examples>
        </section>

        <section type="reference" id="technical-implementation">
            <code-examples>
                <example type="model-selection">
                    <code language="python">
def select_model(requirements):
    """Smart model selection based on requirements"""
    if requirements.get('testing'):
        return "eleven_flash_v2_5"  # Cheapest for development

    if requirements.get('emotional_range'):
        return "eleven_v3_alpha"  # Best expressiveness

    if requirements.get('languages') > 1:
        return "eleven_turbo_v2_5"  # Multilingual support

    if requirements.get('language') == 'english':
        return "eleven_turbo_v2"  # Optimized for English

    return "eleven_turbo_v2_5"  # Safe default
                    </code>
                </example>

                <example type="api-ids">
                    <code language="python">
MODELS = {
    'flash': 'eleven_flash_v2_5',
    'turbo_english': 'eleven_turbo_v2',
    'turbo_multi': 'eleven_turbo_v2_5',
    'expressive': 'eleven_v3_alpha',
    'legacy': 'eleven_multilingual_v2'
}
                    </code>
                </example>
            </code-examples>
        </section>

        <section type="troubleshooting" id="common-issues">
            <examples>
                <example type="anti-pattern">
                    <scenario>Using v3 without proper prompt engineering</scenario>
                    <implementation>Raw text input without emotional tags or context</implementation>
                    <explanation>v3 requires structured prompts with emotional cues like [whispers], [laughs] for optimal results</explanation>
                </example>

                <example type="cost-optimization">
                    <scenario>Unexpected high costs during testing</scenario>
                    <implementation>Using Turbo or v3 for iterative development</implementation>
                    <explanation>Use Flash v2.5 for testing and development to minimize costs before production</explanation>
                </example>
            </examples>

            <validation>
                <validation-command>curl -X GET "https://api.elevenlabs.io/v1/models" -H "xi-api-key: YOUR_KEY"</validation-command>
                <success-criteria>Returns JSON with current model specifications and availability</success-criteria>
            </validation>
        </section>

        <section type="advanced" id="advanced-usage">
            <technical-explanation>
                Advanced model selection strategies, performance optimization techniques, and production deployment patterns including model mixing, caching strategies, and fallback implementations.
            </technical-explanation>
            <simple-explanation>
                Pro techniques for getting the best results and saving money, like using different models for different parts of your podcast.
            </simple-explanation>

            <examples>
                <example type="advanced">
                    <scenario>Mixed-model production workflow</scenario>
                    <implementation>Flash for narration, v3 for quotes and emotional segments, caching for repeated elements</implementation>
                    <explanation>Optimize costs by matching model capabilities to content requirements while maintaining quality</explanation>
                </example>

                <example type="migration">
                    <scenario>Production phase migration strategy</scenario>
                    <implementation>Walk: Flash testing → Crawl: v3 discounted production → Run: Turbo v2.5 stable</implementation>
                    <explanation>Progressive model adoption aligned with learning phases and cost optimization</explanation>
                </example>
            </examples>
        </section>
    </content>

    <cross-references>
        <reference file="00_elevenlabs_constants.xml" section="model-specifications" type="prerequisite">
            Model specifications and current pricing constants
        </reference>
        <reference file="15_elevenlabs_overview.xml" section="overview" type="prerequisite">
            ElevenLabs platform introduction and setup
        </reference>
        <reference file="17_elevenlabs_prompt_engineering.xml" section="model-specific" type="related">
            Model-specific prompt engineering techniques
        </reference>
        <reference file="20_elevenlabs_cost_optimization.xml" section="model-selection" type="related">
            Advanced cost optimization strategies
        </reference>
    </cross-references>
</document>
